{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Reproduce_Sepsis_Paper.ipynb","provenance":[],"mount_file_id":"1yIH_9R3KzLF9QpqxhY1xE8t3FQ_DS3lF","authorship_tag":"ABX9TyNfwFYuLOOkNQza598C+1Kc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Here, the data is loaded into a pandas dataframe from my Google drive. The data is posted with the paper by Hou et al., at https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-020-02620-5#availability-of-data-and-materials"],"metadata":{"id":"o9eq3DTyUFoB"}},{"cell_type":"code","execution_count":25,"metadata":{"id":"TAXw_zT2MzzG","executionInfo":{"status":"ok","timestamp":1652042664989,"user_tz":300,"elapsed":148,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}}},"outputs":[],"source":["import pandas as pd\n","\n","sepsis_df = pd.read_csv(\"/content/drive/MyDrive/CS 598 - Deep Learning for Healthcare/Final Project/Reproducing Septic Paper/sepsis_data.csv\")"]},{"cell_type":"markdown","source":["Here, we can see the columns from this dataset, which include demographic information, vital signs, and lab results."],"metadata":{"id":"Qkl9UJplUTkx"}},{"cell_type":"code","source":["for col in sepsis_df.columns:\n","  print(col)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j84FJBBlNItS","executionInfo":{"status":"ok","timestamp":1652042666102,"user_tz":300,"elapsed":127,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"a3152d77-7004-49d4-ba03-651d6dec04d8"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["icustay_id\n","hadm_id\n","intime\n","outtime\n","dbsource\n","suspected_infection_time_poe\n","suspected_infection_time_poe_days\n","specimen_poe\n","positiveculture_poe\n","antibiotic_time_poe\n","blood_culture_time\n","blood_culture_positive\n","age\n","gender\n","is_male\n","ethnicity\n","race_white\n","race_black\n","race_hispanic\n","race_other\n","metastatic_cancer\n","diabetes\n","first_service\n","hospital_expire_flag\n","thirtyday_expire_flag\n","icu_los\n","hosp_los\n","sepsis_angus\n","sepsis_martin\n","sepsis_explicit\n","septic_shock_explicit\n","severe_sepsis_explicit\n","sepsis_nqf\n","sepsis_cdc\n","sepsis_cdc_simple\n","elixhauser_hospital\n","vent\n","sofa\n","lods\n","sirs\n","qsofa\n","qsofa_sysbp_score\n","qsofa_gcs_score\n","qsofa_resprate_score\n","aniongap_min\n","aniongap_max\n","bicarbonate_min\n","bicarbonate_max\n","creatinine_min\n","creatinine_max\n","chloride_min\n","chloride_max\n","glucose_min\n","glucose_max\n","hematocrit_min\n","hematocrit_max\n","hemoglobin_min\n","hemoglobin_max\n","lactate_min\n","lactate_max\n","lactate_mean\n","platelet_min\n","platelet_max\n","potassium_min\n","potassium_max\n","inr_min\n","inr_max\n","sodium_min\n","sodium_max\n","bun_min\n","bun_max\n","bun_mean\n","wbc_min\n","wbc_max\n","wbc_mean\n","heartrate_min\n","heartrate_max\n","heartrate_mean\n","sysbp_min\n","sysbp_max\n","sysbp_mean\n","diasbp_min\n","diasbp_max\n","diasbp_mean\n","meanbp_min\n","meanbp_max\n","meanbp_mean\n","resprate_min\n","resprate_max\n","resprate_mean\n","tempc_min\n","tempc_max\n","tempc_mean\n","spo2_min\n","spo2_max\n","spo2_mean\n","glucose_min1\n","glucose_max1\n","glucose_mean\n","rrt\n","subject_id\n","hadm_id.1\n","icustay_id.1\n","urineoutput\n","colloid_bolus\n","crystalloid_bolus\n"]}]},{"cell_type":"markdown","source":["We confirm that there are no missing values in the target, which is thirtyday_expire_flag, indicating whether or not the patient died within 30 days."],"metadata":{"id":"XB-ZIKDAHNf8"}},{"cell_type":"code","source":["sepsis_df[\"thirtyday_expire_flag\"].isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fLeQ6wkeHFXq","executionInfo":{"status":"ok","timestamp":1652042666913,"user_tz":300,"elapsed":217,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"72386738-6ec9-41ed-8bc5-560546898a32"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["We look at the value counts for the target, seeing that there are 3670 patients who survived, and 889 patients who died within 30 days. We see that we have a class imbalance, with 80.5% of patients surviving."],"metadata":{"id":"QOlTisjTUmus"}},{"cell_type":"code","source":["sepsis_df[\"thirtyday_expire_flag\"].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZ_CN0PENLII","executionInfo":{"status":"ok","timestamp":1652042667580,"user_tz":300,"elapsed":3,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"a820c760-ca0b-4b74-eeaf-53506b5f7db0"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    3670\n","1     889\n","Name: thirtyday_expire_flag, dtype: int64"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["Now, we select the target."],"metadata":{"id":"poMpN8lRPnwQ"}},{"cell_type":"code","source":["y = sepsis_df[\"thirtyday_expire_flag\"]"],"metadata":{"id":"NdYn1Ze5PnMm","executionInfo":{"status":"ok","timestamp":1652042668665,"user_tz":300,"elapsed":141,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Next, we drop columns that are not used for prediction. Note that gender and ethnicity are one-hot encoded, and these one-hot encoded variables are still included in the dataset."],"metadata":{"id":"UwdsTnwsO2GJ"}},{"cell_type":"code","source":["to_drop = [\"icustay_id\",\n","           \"hadm_id\",\n","           \"intime\",\n","           \"outtime\",\n","           \"dbsource\",\n","           \"suspected_infection_time_poe\",\n","           \"suspected_infection_time_poe_days\",\n","           \"specimen_poe\",\n","           \"positiveculture_poe\",\n","           \"antibiotic_time_poe\",\n","           \"blood_culture_time\",\n","           \"blood_culture_positive\",\n","           \"gender\",\n","           \"ethnicity\",\n","           \"hospital_expire_flag\",\n","           \"thirtyday_expire_flag\",\n","           \"first_service\"]\n","\n","X = sepsis_df.drop(columns = to_drop)"],"metadata":{"id":"YhxCrv2tOEff","executionInfo":{"status":"ok","timestamp":1652042670056,"user_tz":300,"elapsed":218,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["We are now left with only numerical features. We perform mean value imputation on all columns to fill in missing values."],"metadata":{"id":"sqSHETGrHQMl"}},{"cell_type":"code","source":["X = X.apply(lambda x:x.fillna(x.mean()), axis = 0).values"],"metadata":{"id":"L7sXicHEHRbg","executionInfo":{"status":"ok","timestamp":1652042671014,"user_tz":300,"elapsed":121,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["Now, we ust the StandardScaler from SciKit-Learn to normalize the data so that each feature has mean 0 and standard deviation 1."],"metadata":{"id":"6KOCeirSVlnb"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)"],"metadata":{"id":"N17KZd1lW7Q4","executionInfo":{"status":"ok","timestamp":1652042672052,"user_tz":300,"elapsed":136,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["We split the data into a training set and a testing set, which we will use to train and evaluate models. The training set is 80% of the data, while the testing set is 20% of the data."],"metadata":{"id":"rzUEK5TWVsmR"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, stratify = y, random_state = 0)"],"metadata":{"id":"Fc-Qt_G3PXtM","executionInfo":{"status":"ok","timestamp":1652042673447,"user_tz":300,"elapsed":112,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["We will use a memory profile to check the computational requirements."],"metadata":{"id":"RNdbsxPubx5U"}},{"cell_type":"code","source":["!pip install memory_profiler\n","%load_ext memory_profiler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3QoYYeJjbtcw","executionInfo":{"status":"ok","timestamp":1652042989879,"user_tz":300,"elapsed":3280,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"c1208bfe-032d-4651-9492-f9da10538f20"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: memory_profiler in /usr/local/lib/python3.7/dist-packages (0.60.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n"]}]},{"cell_type":"markdown","source":["Next, we train our first model, which is logistic regression. We use the model classifier from SciKit-Learn, and fit it to the training data. We evaluate the performance by computing the accuracy, precision, recall, and AUC on the testing data."],"metadata":{"id":"qtZ6mOn4WEdm"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","clf = LogisticRegression(random_state = 0, max_iter = 10000)\n","%time %memit clf.fit(X_train, y_train)\n","\n","y_pred = clf.predict(X_test)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Precision:\", precision_score(y_test, y_pred))\n","print(\"Recall:\", recall_score(y_test, y_pred))\n","print(\"AUC:\", roc_auc_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LsjRvJLGUEQV","executionInfo":{"status":"ok","timestamp":1652043000488,"user_tz":300,"elapsed":773,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"a56123cf-348a-4fc1-e5a1-7fe5db9ef6e6"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["peak memory: 296.12 MiB, increment: 0.02 MiB\n","CPU times: user 402 ms, sys: 160 ms, total: 562 ms\n","Wall time: 761 ms\n","Accuracy: 0.8848684210526315\n","Precision: 0.7967479674796748\n","Recall: 0.550561797752809\n","AUC: 0.758250926124361\n"]}]},{"cell_type":"markdown","source":["Our next model is a support vector machine classifier. Again, we use the model from SciKit-Learn. Below, I include the SVC with the default kernel: rbf. I experimented with other kernels, and found that this gave the best performance."],"metadata":{"id":"YOu8kTQsWeXA"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","clf = SVC(random_state = 0)\n","%time %memit clf.fit(X_train, y_train)\n","\n","y_pred = clf.predict(X_test)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Precision:\", precision_score(y_test, y_pred))\n","print(\"Recall:\", recall_score(y_test, y_pred))\n","print(\"AUC:\", roc_auc_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xQIaM7xYUlz","executionInfo":{"status":"ok","timestamp":1652043212849,"user_tz":300,"elapsed":2705,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"c7e804e9-fcde-4921-855c-46a0e61ee60d"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["peak memory: 296.14 MiB, increment: 0.03 MiB\n","CPU times: user 1.28 s, sys: 108 ms, total: 1.39 s\n","Wall time: 2.32 s\n","Accuracy: 0.8651315789473685\n","Precision: 0.8767123287671232\n","Recall: 0.3595505617977528\n","AUC: 0.6736444907081407\n"]}]},{"cell_type":"markdown","source":["Next, I used a random forest classifier."],"metadata":{"id":"YI7RyN3kWyrG"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","clf = RandomForestClassifier(random_state = 0)\n","%time %memit clf.fit(X_train, y_train)\n","\n","y_pred = clf.predict(X_test)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Precision:\", precision_score(y_test, y_pred))\n","print(\"Recall:\", recall_score(y_test, y_pred))\n","print(\"AUC:\", roc_auc_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQxRY2rNYmLK","executionInfo":{"status":"ok","timestamp":1652043249772,"user_tz":300,"elapsed":5888,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"434f2952-471b-4893-bc69-6521869801d4"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["peak memory: 296.29 MiB, increment: 0.00 MiB\n","CPU times: user 2.85 s, sys: 39.2 ms, total: 2.89 s\n","Wall time: 5.53 s\n","Accuracy: 0.8739035087719298\n","Precision: 0.9315068493150684\n","Recall: 0.38202247191011235\n","AUC: 0.6876052414046474\n"]}]},{"cell_type":"markdown","source":["Now, we try a gradient boosting classifier. Note that the result should be essentially the same as XGBoost, except that XGBoost typically runs faster."],"metadata":{"id":"pr5wdMnNW66v"}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","clf = GradientBoostingClassifier(random_state = 0)\n","%time %memit clf.fit(X_train, y_train)\n","\n","y_pred = clf.predict(X_test)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Precision:\", precision_score(y_test, y_pred))\n","print(\"Recall:\", recall_score(y_test, y_pred))\n","print(\"AUC:\", roc_auc_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtwqDxf1Y7iJ","executionInfo":{"status":"ok","timestamp":1652043277003,"user_tz":300,"elapsed":7424,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"60ad8a26-57d4-42d2-b4cb-c35318f7195e"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["peak memory: 296.34 MiB, increment: 0.00 MiB\n","CPU times: user 6.61 s, sys: 39.8 ms, total: 6.65 s\n","Wall time: 7.28 s\n","Accuracy: 0.8980263157894737\n","Precision: 0.8761061946902655\n","Recall: 0.5561797752808989\n","AUC: 0.768553102899305\n"]}]},{"cell_type":"markdown","source":["Next, we try a $k$-nearest neighbors classifier. From experimenting with the value our $k$, we found that $k = 1$ gave the best performance (though this is most likely overfitting)."],"metadata":{"id":"JXSSQFTAXhaH"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","clf = KNeighborsClassifier(n_neighbors = 1)\n","%time %memit clf.fit(X_train, y_train)\n","\n","y_pred = clf.predict(X_test)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Precision:\", precision_score(y_test, y_pred))\n","print(\"Recall:\", recall_score(y_test, y_pred))\n","print(\"AUC:\", roc_auc_score(y_test, y_pred))"],"metadata":{"id":"w2J8hMDFbTq-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652043300010,"user_tz":300,"elapsed":686,"user":{"displayName":"Melissa Lynn","userId":"10784518892206740494"}},"outputId":"8948be09-02e3-461f-e4c5-ddb39fec71e1"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["peak memory: 296.34 MiB, increment: 0.00 MiB\n","CPU times: user 198 ms, sys: 98.6 ms, total: 296 ms\n","Wall time: 535 ms\n","Accuracy: 0.8026315789473685\n","Precision: 0.49166666666666664\n","Recall: 0.33146067415730335\n","AUC: 0.6241772035636654\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"1syzRzrcXxWQ"},"execution_count":null,"outputs":[]}]}